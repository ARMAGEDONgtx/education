{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "my_init = initializers.glorot_uniform(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = load_raw_data(data_folder)\n",
    "X, Y, Y_std, Y_soc, Y_fourier = prepare_x_y(X, Y)\n",
    "X_train, X_test, Y_train, Y_test, Y_train_std, Y_test_std, \\\n",
    "                     Y_train_soc, Y_test_soc, Y_train_fourier, Y_test_fourier = prepare_train_test(X, \n",
    "                                                                                                   Y, \n",
    "                                                                                                   Y_std, \n",
    "                                                                                                   Y_soc, \n",
    "                                                                                                   Y_fourier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.02      0.02      0.02       102\n",
      "          2       0.00      0.00      0.00        20\n",
      "          3       0.00      0.00      0.00        31\n",
      "          4       0.00      0.00      0.00        42\n",
      "          5       0.45      0.13      0.20       100\n",
      "          6       0.00      0.00      0.00        20\n",
      "          7       0.00      0.00      0.00         5\n",
      "          8       0.00      0.00      0.00         3\n",
      "          9       0.21      0.69      0.32       101\n",
      "         10       0.00      0.00      0.00        20\n",
      "         11       0.00      0.00      0.00        28\n",
      "         12       0.25      0.73      0.37       100\n",
      "         13       0.00      0.00      0.00        20\n",
      "         14       0.00      0.00      0.00       100\n",
      "         15       0.00      0.00      0.00        20\n",
      "         16       0.22      0.27      0.24       102\n",
      "         17       0.00      0.00      0.00        20\n",
      "         18       0.00      0.00      0.00        13\n",
      "         19       0.07      0.04      0.05       100\n",
      "         20       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.12      0.19      0.12       979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_feature(Y, Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92        12\n",
      "          1       0.40      0.73      0.52       102\n",
      "          2       0.00      0.00      0.00        20\n",
      "          3       0.00      0.00      0.00        31\n",
      "          4       0.00      0.00      0.00        42\n",
      "          5       0.21      0.30      0.25       100\n",
      "          6       0.00      0.00      0.00        20\n",
      "          7       0.00      0.00      0.00         5\n",
      "          8       0.00      0.00      0.00         3\n",
      "          9       0.31      0.42      0.35       101\n",
      "         10       0.00      0.00      0.00        20\n",
      "         11       0.00      0.00      0.00        28\n",
      "         12       0.33      0.19      0.24       100\n",
      "         13       0.00      0.00      0.00        20\n",
      "         14       0.22      0.02      0.04       100\n",
      "         15       0.00      0.00      0.00        20\n",
      "         16       0.27      0.76      0.40       102\n",
      "         17       0.00      0.00      0.00        20\n",
      "         18       0.00      0.00      0.00        13\n",
      "         19       0.56      0.81      0.66       100\n",
      "         20       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.25      0.34      0.26       979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_feature(Y, Y_soc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        12\n",
      "          1       0.84      0.84      0.84       102\n",
      "          2       1.00      1.00      1.00        20\n",
      "          3       0.74      0.94      0.83        31\n",
      "          4       1.00      1.00      1.00        42\n",
      "          5       0.75      0.92      0.83       100\n",
      "          6       0.60      0.15      0.24        20\n",
      "          7       1.00      1.00      1.00         5\n",
      "          8       1.00      1.00      1.00         3\n",
      "          9       0.52      0.75      0.61       101\n",
      "         10       0.79      0.55      0.65        20\n",
      "         11       0.53      0.32      0.40        28\n",
      "         12       0.76      0.91      0.83       100\n",
      "         13       0.86      0.30      0.44        20\n",
      "         14       0.66      0.52      0.58       100\n",
      "         15       0.50      0.25      0.33        20\n",
      "         16       0.58      0.49      0.53       102\n",
      "         17       0.62      0.50      0.56        20\n",
      "         18       0.53      0.69      0.60        13\n",
      "         19       0.86      0.83      0.85       100\n",
      "         20       1.00      0.95      0.97        20\n",
      "\n",
      "avg / total       0.73      0.73      0.72       979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_feature(Y, Y_fourier, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noEtSIwx0SWrE/wKv96UdcN/7ngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist([np.argmax(y) for y in Y_train], label = 'Train set', alpha = 0.5, bins = 21)\n",
    "plt.hist([np.argmax(y) for y in Y_test], label = 'Test set', alpha = 0.5, bins = 21)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining single task model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inn = Input(shape = (X_train.shape[1], X_train.shape[2], ))\n",
    "\n",
    "x = Conv1D(16, 5, activation='relu', kernel_initializer=my_init)(inn)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(32, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(64, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "out = Dense(Y_test.shape[1], activation = 'softmax', kernel_initializer=my_init)(x)\n",
    "\n",
    "model = Model(inputs=[inn], outputs=[out])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics = ['accuracy'], optimizer = Adam(clipnorm = 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 9318, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 9314, 16)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1862, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1858, 32)          2592      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 371, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 367, 64)           10304     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 21)                1365      \n",
      "=================================================================\n",
      "Total params: 14,517\n",
      "Trainable params: 14,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 734 samples, validate on 245 samples\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - 7s 9ms/step - loss: 8.0418 - acc: 0.1308 - val_loss: 6.3954 - val_acc: 0.1551\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 4.6429 - acc: 0.2125 - val_loss: 3.3135 - val_acc: 0.2041\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 2.5652 - acc: 0.2684 - val_loss: 2.4551 - val_acc: 0.2816\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - 7s 9ms/step - loss: 1.9675 - acc: 0.4046 - val_loss: 1.9489 - val_acc: 0.4490\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - 6s 9ms/step - loss: 1.5944 - acc: 0.4959 - val_loss: 1.6776 - val_acc: 0.4735\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.3541 - acc: 0.5722 - val_loss: 1.5143 - val_acc: 0.4571\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - 6s 9ms/step - loss: 1.1787 - acc: 0.6063 - val_loss: 1.3906 - val_acc: 0.4531\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.0393 - acc: 0.6567 - val_loss: 1.3155 - val_acc: 0.4857\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 0.9267 - acc: 0.6812 - val_loss: 1.2101 - val_acc: 0.5388\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - 6s 9ms/step - loss: 0.8257 - acc: 0.7153 - val_loss: 1.1196 - val_acc: 0.5714\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs = 10,\n",
    "    batch_size = 64,\n",
    "    validation_data = (X_test, Y_test),\n",
    "    verbose = True,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       0.50      0.31      0.38        26\n",
      "          2       0.43      1.00      0.60         3\n",
      "          3       0.64      0.78      0.70         9\n",
      "          4       0.67      0.25      0.36        16\n",
      "          5       0.63      0.96      0.76        23\n",
      "          6       0.00      0.00      0.00         4\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.56      0.68      0.61        22\n",
      "         10       0.67      0.57      0.62         7\n",
      "         11       0.50      0.20      0.29        10\n",
      "         12       0.71      0.86      0.77        28\n",
      "         13       0.83      0.83      0.83         6\n",
      "         14       0.71      0.60      0.65        25\n",
      "         15       0.71      1.00      0.83         5\n",
      "         16       1.00      0.16      0.28        25\n",
      "         17       0.67      1.00      0.80         2\n",
      "         18       0.00      0.00      0.00         4\n",
      "         19       0.29      0.64      0.39        22\n",
      "         20       0.50      1.00      0.67         3\n",
      "\n",
      "avg / total       0.61      0.57      0.54       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report([np.argmax(x) for x in Y_test], \n",
    "                            [np.argmax(x) for x in model.predict(X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask model + std as auxiliary loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inn = Input(shape = (X_train.shape[1], X_train.shape[2], ))\n",
    "\n",
    "x = Conv1D(16, 5, activation='relu', kernel_initializer=my_init)(inn)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(32, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(64, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "out = Dense(Y_test.shape[1], activation = 'softmax', name = 'classification', kernel_initializer=my_init)(x)\n",
    "out2 = Dense(1, activation = 'linear', name = 'regression', kernel_initializer=my_init)(x)\n",
    "\n",
    "model = Model(inputs=[inn], outputs=[out, out2])\n",
    "\n",
    "model.compile(loss=['categorical_crossentropy', 'mse'],\n",
    "              metrics = {'classification': 'accuracy'}, optimizer = Adam(clipnorm = 1.), loss_weights = [1, 1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 734 samples, validate on 245 samples\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - 7s 9ms/step - loss: 7.9814 - classification_loss: 7.8782 - regression_loss: 103.1249 - classification_acc: 0.1349 - val_loss: 6.4014 - val_classification_loss: 6.3912 - val_regression_loss: 10.1692 - val_classification_acc: 0.1510\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 4.7038 - classification_loss: 4.6947 - regression_loss: 9.0751 - classification_acc: 0.2302 - val_loss: 3.5891 - val_classification_loss: 3.5805 - val_regression_loss: 8.5808 - val_classification_acc: 0.2449\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 2.6548 - classification_loss: 2.6413 - regression_loss: 13.4394 - classification_acc: 0.2793 - val_loss: 2.4982 - val_classification_loss: 2.4777 - val_regression_loss: 20.4502 - val_classification_acc: 0.2816\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.9948 - classification_loss: 1.9783 - regression_loss: 16.4503 - classification_acc: 0.4251 - val_loss: 1.9488 - val_classification_loss: 1.9375 - val_regression_loss: 11.2908 - val_classification_acc: 0.4490\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.6017 - classification_loss: 1.5888 - regression_loss: 12.9415 - classification_acc: 0.5095 - val_loss: 1.7273 - val_classification_loss: 1.7159 - val_regression_loss: 11.4528 - val_classification_acc: 0.5143\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.3681 - classification_loss: 1.3551 - regression_loss: 12.9716 - classification_acc: 0.5586 - val_loss: 1.5497 - val_classification_loss: 1.5384 - val_regression_loss: 11.2550 - val_classification_acc: 0.4694\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.1655 - classification_loss: 1.1527 - regression_loss: 12.7573 - classification_acc: 0.6172 - val_loss: 1.3746 - val_classification_loss: 1.3632 - val_regression_loss: 11.3918 - val_classification_acc: 0.4816\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.0271 - classification_loss: 1.0144 - regression_loss: 12.7584 - classification_acc: 0.6567 - val_loss: 1.2406 - val_classification_loss: 1.2300 - val_regression_loss: 10.6112 - val_classification_acc: 0.5429\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 0.8988 - classification_loss: 0.8862 - regression_loss: 12.5702 - classification_acc: 0.6880 - val_loss: 1.1781 - val_classification_loss: 1.1674 - val_regression_loss: 10.6954 - val_classification_acc: 0.5551\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 0.8062 - classification_loss: 0.7939 - regression_loss: 12.2910 - classification_acc: 0.7207 - val_loss: 1.0752 - val_classification_loss: 1.0650 - val_regression_loss: 10.1562 - val_classification_acc: 0.6000\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    X_train, [Y_train, Y_train_std],\n",
    "    epochs = 10,\n",
    "    batch_size = 64,\n",
    "    validation_data = (X_test, [Y_test, Y_test_std]),\n",
    "    verbose = True,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       0.35      0.62      0.44        26\n",
      "          2       0.50      1.00      0.67         3\n",
      "          3       0.75      0.67      0.71         9\n",
      "          4       0.75      0.19      0.30        16\n",
      "          5       0.62      1.00      0.77        23\n",
      "          6       0.00      0.00      0.00         4\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.68      0.68      0.68        22\n",
      "         10       0.70      1.00      0.82         7\n",
      "         11       0.67      0.40      0.50        10\n",
      "         12       0.81      0.89      0.85        28\n",
      "         13       1.00      0.83      0.91         6\n",
      "         14       0.76      0.64      0.70        25\n",
      "         15       0.71      1.00      0.83         5\n",
      "         16       0.64      0.28      0.39        25\n",
      "         17       0.67      1.00      0.80         2\n",
      "         18       0.00      0.00      0.00         4\n",
      "         19       0.18      0.18      0.18        22\n",
      "         20       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.61      0.60      0.57       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report([np.argmax(x) for x in Y_test], \n",
    "                            [np.argmax(x) for x in model.predict(X_test)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multitask model + sum of change as auxiliary loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inn = Input(shape = (X_train.shape[1], X_train.shape[2], ))\n",
    "\n",
    "x = Conv1D(16, 5, activation='relu', kernel_initializer=my_init)(inn)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(32, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(64, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "out = Dense(Y_test.shape[1], activation = 'softmax', name = 'classification', kernel_initializer=my_init)(x)\n",
    "out2 = Dense(1, activation = 'linear', name = 'regression', kernel_initializer=my_init)(x)\n",
    "\n",
    "model = Model(inputs=[inn], outputs=[out, out2])\n",
    "\n",
    "model.compile(loss=['categorical_crossentropy', 'mse'],\n",
    "              metrics = {'classification': 'accuracy'}, optimizer = Adam(clipnorm = 1.), loss_weights = [1, 1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 734 samples, validate on 245 samples\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - 7s 9ms/step - loss: 11.1478 - classification_loss: 8.0318 - regression_loss: 3115966.6839 - classification_acc: 0.1308 - val_loss: 8.9401 - val_classification_loss: 6.3911 - val_regression_loss: 2548998.4939 - val_classification_acc: 0.1673\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - 6s 9ms/step - loss: 7.7702 - classification_loss: 4.6649 - regression_loss: 3105226.9428 - classification_acc: 0.2153 - val_loss: 5.8648 - val_classification_loss: 3.3222 - val_regression_loss: 2542660.2918 - val_classification_acc: 0.2082\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - 7s 9ms/step - loss: 5.6565 - classification_loss: 2.5536 - regression_loss: 3102907.6458 - classification_acc: 0.2738 - val_loss: 5.0089 - val_classification_loss: 2.4654 - val_regression_loss: 2543461.0959 - val_classification_acc: 0.2776\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 5.0711 - classification_loss: 1.9695 - regression_loss: 3101594.1826 - classification_acc: 0.4223 - val_loss: 4.4836 - val_classification_loss: 1.9428 - val_regression_loss: 2540833.5796 - val_classification_acc: 0.4490\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 4.7213 - classification_loss: 1.6222 - regression_loss: 3099138.3678 - classification_acc: 0.5014 - val_loss: 4.2740 - val_classification_loss: 1.7370 - val_regression_loss: 2536963.7429 - val_classification_acc: 0.4939\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 4.4756 - classification_loss: 1.3813 - regression_loss: 3094362.0736 - classification_acc: 0.5722 - val_loss: 4.0726 - val_classification_loss: 1.5405 - val_regression_loss: 2532142.4959 - val_classification_acc: 0.4653\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 4.2760 - classification_loss: 1.1871 - regression_loss: 3088857.2425 - classification_acc: 0.6131 - val_loss: 3.9077 - val_classification_loss: 1.3810 - val_regression_loss: 2526676.3408 - val_classification_acc: 0.4857\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 4.1207 - classification_loss: 1.0377 - regression_loss: 3083017.6730 - classification_acc: 0.6431 - val_loss: 3.7755 - val_classification_loss: 1.2549 - val_regression_loss: 2520593.6510 - val_classification_acc: 0.5265\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 3.9895 - classification_loss: 0.9137 - regression_loss: 3075812.6975 - classification_acc: 0.6866 - val_loss: 3.6542 - val_classification_loss: 1.1408 - val_regression_loss: 2513396.7796 - val_classification_acc: 0.5796\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 3.8673 - classification_loss: 0.7999 - regression_loss: 3067344.8093 - classification_acc: 0.7221 - val_loss: 3.5692 - val_classification_loss: 1.0645 - val_regression_loss: 2504744.2367 - val_classification_acc: 0.5959\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    X_train, [Y_train, Y_train_soc],\n",
    "    epochs = 10,\n",
    "    batch_size = 64,\n",
    "    validation_data = (X_test, [Y_test, Y_test_soc]),\n",
    "    verbose = True,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       0.42      0.38      0.40        26\n",
      "          2       0.43      1.00      0.60         3\n",
      "          3       0.67      0.67      0.67         9\n",
      "          4       0.73      0.69      0.71        16\n",
      "          5       0.63      0.96      0.76        23\n",
      "          6       0.00      0.00      0.00         4\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.67      0.73      0.70        22\n",
      "         10       0.75      0.43      0.55         7\n",
      "         11       0.33      0.10      0.15        10\n",
      "         12       0.75      0.86      0.80        28\n",
      "         13       0.80      0.67      0.73         6\n",
      "         14       0.67      0.64      0.65        25\n",
      "         15       0.71      1.00      0.83         5\n",
      "         16       0.68      0.52      0.59        25\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       0.00      0.00      0.00         4\n",
      "         19       0.22      0.27      0.24        22\n",
      "         20       0.50      1.00      0.67         3\n",
      "\n",
      "avg / total       0.57      0.60      0.57       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report([np.argmax(x) for x in Y_test], \n",
    "                            [np.argmax(x) for x in model.predict(X_test)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask model + Fourier coefs as auxiliary loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inn = Input(shape = (X_train.shape[1], X_train.shape[2], ))\n",
    "\n",
    "x = Conv1D(16, 5, activation='relu', kernel_initializer=my_init)(inn)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(32, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(64, 5, activation='relu', kernel_initializer=my_init)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "out = Dense(Y_test.shape[1], activation = 'softmax', name = 'classification', kernel_initializer=my_init)(x)\n",
    "out2 = Dense(Y_train_fourier.shape[1], activation = 'linear', name = 'regression', kernel_initializer=my_init)(x)\n",
    "\n",
    "model = Model(inputs=[inn], outputs=[out, out2])\n",
    "\n",
    "model.compile(loss=['categorical_crossentropy', 'mse'],\n",
    "              metrics = {'classification': 'accuracy'}, optimizer = Adam(clipnorm = 1.), loss_weights = [1, 1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 734 samples, validate on 245 samples\n",
      "Epoch 1/10\n",
      "734/734 [==============================] - 7s 9ms/step - loss: 8.1410 - classification_loss: 7.8511 - regression_loss: 28.9874 - classification_acc: 0.1281 - val_loss: 6.1778 - val_classification_loss: 6.0995 - val_regression_loss: 7.8250 - val_classification_acc: 0.1633\n",
      "Epoch 2/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 4.0594 - classification_loss: 4.0178 - regression_loss: 4.1614 - classification_acc: 0.1757 - val_loss: 2.9085 - val_classification_loss: 2.8890 - val_regression_loss: 1.9509 - val_classification_acc: 0.2286\n",
      "Epoch 3/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 2.3775 - classification_loss: 2.3581 - regression_loss: 1.9350 - classification_acc: 0.3106 - val_loss: 2.3183 - val_classification_loss: 2.2984 - val_regression_loss: 1.9896 - val_classification_acc: 0.2939\n",
      "Epoch 4/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.8467 - classification_loss: 1.8303 - regression_loss: 1.6432 - classification_acc: 0.4414 - val_loss: 1.9211 - val_classification_loss: 1.9058 - val_regression_loss: 1.5276 - val_classification_acc: 0.4531\n",
      "Epoch 5/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.5664 - classification_loss: 1.5505 - regression_loss: 1.5886 - classification_acc: 0.5327 - val_loss: 1.7050 - val_classification_loss: 1.6893 - val_regression_loss: 1.5691 - val_classification_acc: 0.4653\n",
      "Epoch 6/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.3632 - classification_loss: 1.3469 - regression_loss: 1.6294 - classification_acc: 0.5545 - val_loss: 1.6088 - val_classification_loss: 1.5937 - val_regression_loss: 1.5096 - val_classification_acc: 0.4286\n",
      "Epoch 7/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.2109 - classification_loss: 1.1961 - regression_loss: 1.4765 - classification_acc: 0.5886 - val_loss: 1.4545 - val_classification_loss: 1.4412 - val_regression_loss: 1.3273 - val_classification_acc: 0.4776\n",
      "Epoch 8/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 1.0650 - classification_loss: 1.0518 - regression_loss: 1.3202 - classification_acc: 0.6226 - val_loss: 1.2989 - val_classification_loss: 1.2870 - val_regression_loss: 1.1865 - val_classification_acc: 0.5429\n",
      "Epoch 9/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 0.9397 - classification_loss: 0.9275 - regression_loss: 1.2207 - classification_acc: 0.6730 - val_loss: 1.1759 - val_classification_loss: 1.1647 - val_regression_loss: 1.1233 - val_classification_acc: 0.5878\n",
      "Epoch 10/10\n",
      "734/734 [==============================] - 6s 8ms/step - loss: 0.8389 - classification_loss: 0.8273 - regression_loss: 1.1643 - classification_acc: 0.6975 - val_loss: 1.0750 - val_classification_loss: 1.0637 - val_regression_loss: 1.1298 - val_classification_acc: 0.6163\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    X_train, [Y_train, Y_train_fourier],\n",
    "    epochs = 10,\n",
    "    batch_size = 64,\n",
    "    validation_data = (X_test, [Y_test, Y_test_fourier]),\n",
    "    verbose = True,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       0.62      0.31      0.41        26\n",
      "          2       0.50      1.00      0.67         3\n",
      "          3       0.70      0.78      0.74         9\n",
      "          4       0.82      0.56      0.67        16\n",
      "          5       0.67      0.96      0.79        23\n",
      "          6       0.00      0.00      0.00         4\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.86      0.55      0.67        22\n",
      "         10       0.83      0.71      0.77         7\n",
      "         11       0.00      0.00      0.00        10\n",
      "         12       0.76      0.93      0.84        28\n",
      "         13       0.80      0.67      0.73         6\n",
      "         14       0.62      0.52      0.57        25\n",
      "         15       0.62      1.00      0.77         5\n",
      "         16       0.60      0.72      0.65        25\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       0.00      0.00      0.00         4\n",
      "         19       0.28      0.59      0.38        22\n",
      "         20       0.75      1.00      0.86         3\n",
      "\n",
      "avg / total       0.60      0.62      0.59       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report([np.argmax(x) for x in Y_test], \n",
    "                            [np.argmax(x) for x in model.predict(X_test)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# homework: to get 65% F1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
